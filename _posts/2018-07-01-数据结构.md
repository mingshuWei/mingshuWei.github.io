---
layout:     post
title:      数据结构
subtitle:   
date:       2018-07-01
author:     mingshu
catalog: true
tags:
    - 数据结构
    - List
    - Map
    - Queue
    - Stack
    - Concurrent*
---

# 数据结构
本系列主要对一些经典的数据结构进行分析。
# List

# Stack

# Queue

# Map
Map 是一个散列表，它存储的内容是键值对(key-value)映射， 提供了O(1)的查找时间（除特殊，android 优化后的两个)。
哈希冲突：
如果两个不同的元素，通过哈希函数得出的实际存储地址相同怎么办？也就是说，当我们对某个元素进行哈希运算，得到一个存储地址，然后要进行插入的时候，发现已经被其他元素占用了，其实这就是所谓的哈希冲突，也叫哈希碰撞。前面我们提到过，哈希函数的设计至关重要，好的哈希函数会尽可能地保证 计算简单和散列地址分布均匀,但是，我们需要清楚的是，数组是一块连续的固定长度的内存空间，再好的哈希函数也不能保证得到的存储地址绝对不发生冲突。那么哈希冲突如何解决呢？哈希冲突的解决方案有多种:开放定址法（发生冲突，继续寻找下一块未被占用的存储地址），再散列函数法，链地址法，而HashMap即是采用了链地址法，也就是数组+链表的方式。
Key的Hash值冲突：
此时必须key的equal 为true 且hash值一样，则替换oldValue。
## HashMap
最基本的Map，有如下特点：
1. HashMap 是一个散列表，它存储的内容是键值对(key-value)映射。
2. HashMap 继承于AbstractMap，实现了Map、Cloneable、java.io.Serializable接口。

HashMap 的实例有两个参数影响其性能：“初始容量” 和 “加载因子”
初始容量：哈希表中桶的数量，数组的长度。
加载因子：哈希表在其容量自动增加之前可以达到多满的一种尺度，默认加载因子是 0.75, 这是在时间和空间成本上寻求一种折衷。加载因子过高虽然减少了空间开销，但同时也增加了查询成本（在大多数 HashMap 类的操作中，包括 get 和 put 操作，都反映了这一点）。

存储节点的数据结构如下：
```
    static class Entry<K,V> implements Map.Entry<K,V> {
        final K key;
        V value;
        Entry<K,V> next;//存储指向下一个Entry的引用，单链表结构
        int hash;//对key的hashcode值进行hash运算后得到的值，存储在Entry，避免重复计算，get put 时使用，判断key 的 hashcode 和 equal

        /**
         * Creates new entry.
         */
        Entry(int h, K k, V v, Entry<K,V> n) {
            value = v;
            next = n;
            key = k;
            hash = h;
        }
    
        // 实现hashCode()
         public final int hashCode() {
             return (key==null   ? 0 : key.hashCode()) ^
                    (value==null ? 0 : value.hashCode());
         }

         // 实现equal
         public final boolean equal(Object o) {
             // key 和 value 都相等
         }
    }
```
HashMap关键参数 关键逻辑:
```
//实际存储的key-value键值对的个数
transient int size;
//阈值，当table == {}时，该值为初始容量（初始容量默认为16）；当table被填充了，也就是为table分配内存空间后，threshold一般为 capacity*loadFactory。HashMap在进行扩容时需要参考threshold，后面会详细谈到
int threshold;
//负载因子，代表了table的填充度有多少，默认是0.75
final float loadFactor;
//用于快速失败，由于HashMap非线程安全，在对HashMap进行迭代时，如果期间其他线程的参与导致HashMap的结构发生变化了（比如put，remove等操作），需要抛出异常ConcurrentModificationException
transient int modCount;
```
put get 操作：
```
public V put(K key, V value) {
        //如果table数组为空数组{}，进行数组填充（为table分配实际内存空间），入参为threshold，此时threshold为initialCapacity 默认是1<<4(24=16)
        if (table == EMPTY_TABLE) {
            inflateTable(threshold);
        }
       //如果key为null，存储位置为table[0]或table[0]的冲突链上
        if (key == null)
            return putForNullKey(value);
        int hash = hash(key);//对key的hashcode进一步计算，确保散列均匀
        int i = indexFor(hash, table.length);//获取在table中的实际位置
        for (Entry<K,V> e = table[i]; e != null; e = e.next) {
        //如果该对应数据已存在，执行覆盖操作。用新value替换旧value，并返回旧value
            Object k;
            if (e.hash == hash && ((k = e.key) == key || key.equals(k))) { //重点理解这一点，*要求key hash值和equal同时满足才行*
                V oldValue = e.value;
                e.value = value;
                e.recordAccess(this);
                return oldValue;
            }
        }
        modCount++;//保证并发访问时，若HashMap内部结构发生变化，快速响应失败 ，若上面两点不能同时满足，则新增加entry
        addEntry(hash, key, value, i);//新增一个entry，判断是否 size > threshold ,resize 2*size
        return null;
    }

    // 获取key对应的value
    public V get(Object key) {
        if (key == null)
            return getForNullKey();
        // 获取key的hash值
        int hash = hash(key.hashCode());
        // 在“该hash值对应的链表”上查找“键值等于key”的元素
        for (Entry<K,V> e = table[indexFor(hash, table.length)];
             e != null;
             e = e.next) {
            Object k;
            if (e.hash == hash && ((k = e.key) == key || key.equals(k)))
                return e.value;
        }
        return null;
    }
```
resize:为何HashMap的数组长度一定是2的次幂？

```
    // 重新调整HashMap的大小，newCapacity是调整后的单位
    void resize(int newCapacity) {
        Entry[] oldTable = table;
        int oldCapacity = oldTable.length;
        if (oldCapacity == MAXIMUM_CAPACITY) {
            threshold = Integer.MAX_VALUE;
            return;
        }

        // 新建一个HashMap，将“旧HashMap”的全部元素添加到“新HashMap”中，
        // 然后，将“新HashMap”赋值给“旧HashMap”。
        Entry[] newTable = new Entry[newCapacity];
        transfer(newTable);
        table = newTable;
        threshold = (int)(newCapacity * loadFactor);
    }

    // 将HashMap中的全部元素都添加到newTable中
    void transfer(Entry[] newTable) {
        Entry[] src = table;
        int newCapacity = newTable.length;
        for (int j = 0; j < src.length; j++) {
            Entry<K,V> e = src[j];
            if (e != null) {
                src[j] = null;
                do {
                    Entry<K,V> next = e.next;
                    int i = indexFor(e.hash, newCapacity);
                    e.next = newTable[i];
                    newTable[i] = e;
                    e = next;
                } while (e != null);
            }
        }
    }
```
hashMap的数组长度一定保持2的次幂，比如16的二进制表示为 10000，那么length-1就是15，二进制为01111，同理扩容后的数组长度为32，二进制表示为100000，length-1为31，二进制表示为011111。从下图可以我们也能看到这样会保证低位全为1，而扩容后只有一位差异，也就是多出了最左位的1，这样在通过 h&(length-1)的时候，只要h对应的最左边的那一个差异位为0，就能保证得到的新的数组索引和老数组索引一致(大大减少了之前已经散列良好的老数组的数据位置重新调换)，个人理解。
还有，数组长度保持2的次幂，length-1的低位都为1，会使得获得的数组索引index更加均匀，比如：
我们看到，上面的&运算，高位是不会对结果产生影响的（hash函数采用各种位运算可能也是为了使得低位更加散列），我们只关注低位bit，如果低位全部为1，那么对于h低位部分来说，任何一位的变化都会对结果产生影响，也就是说，要得到index=21这个存储位置，h的低位只有这一种组合。这也是数组长度设计为必须为2的次幂的原因。
> https://www.cnblogs.com/chengxiao/p/6059914.html

entrySet()、values()、keySet():
它们3个的原理类似，这里以entrySet()为例来说明。
entrySet()的作用是返回“HashMap中所有Entry的集合”，它是一个集合。实现代码如下：
```
// 返回“HashMap的Entry集合”
public Set<Map.Entry<K,V>> entrySet() {
    return entrySet0();
}

// 返回“HashMap的Entry集合”，它实际是返回一个EntrySet对象
private Set<Map.Entry<K,V>> entrySet0() {
    Set<Map.Entry<K,V>> es = entrySet;
    return es != null ? es : (entrySet = new EntrySet());
}

// EntrySet对应的集合
// EntrySet继承于AbstractSet，说明该集合中没有重复的EntrySet。
private final class EntrySet extends AbstractSet<Map.Entry<K,V>> {
    public Iterator<Map.Entry<K,V>> iterator() {
        return newEntryIterator();
    }
    public boolean contains(Object o) {
        if (!(o instanceof Map.Entry))
            return false;
        Map.Entry<K,V> e = (Map.Entry<K,V>) o;
        Entry<K,V> candidate = getEntry(e.getKey());
        return candidate != null && candidate.equals(e);
    }
    public boolean remove(Object o) {
        return removeMapping(o) != null;
    }
    public int size() {
        return size;
    }
    public void clear() {
        HashMap.this.clear();
    }
}
```
为何重写equal时，一定要复写hashcode
如果我们已经对HashMap的原理有了一定了解，这个结果就不难理解了。尽管我们在进行get和put操作的时候，使用的key从逻辑上讲是等值的（通过equals比较是相等的），但由于没有重写hashCode方法，所以put操作时，key(hashcode1)-->hash-->indexFor-->最终索引位置 ，而通过key取出value的时候 key(hashcode1)-->hash-->indexFor-->最终索引位置，由于hashcode1不等于hashcode2，导致没有定位到一个数组位置而返回逻辑上错误的值null（也有可能碰巧定位到一个数组位置，但是也会判断其entry的hash值是否相等，上面get方法中有提到。）
所以，在重写equals的方法的时候，必须注意重写hashCode方法，同时还要保证通过equals判断相等的两个对象，调用hashCode方法要返回同样的整数值。而如果equals判断不相等的两个对象，其hashCode可以相同（只不过会发生哈希冲突，应尽量避免）。

## ConcurrentHashMap

## LinkedHashMap

## WeakHashMap
WeakHashMap 用来设计缓存系统，归根到底，是个Java GC的问题，由垃圾回收器与ReferenceQueue的交互方式决定。WeakHashMap 的核心原理是 ReferenceQueue 这个“监听器”来优雅的实现自动删除那些引用不可达的key的。
ReferenceQueue 在java doc 中的定义为
> Reference queues, to which registered reference objects are appended by the garbage collector after the appropriate reachability changes are detected. 
> 中文JavaDoc的描述：引用队列，在检测到适当的可到达性更改后，垃圾回收器将已注册的引用对象添加到该队列中
查看源代码会发现它很简单，实现了一个队列的入队(enqueue)和出队(poll还有remove)操作，内部元素就是泛型的Reference，并且Queue的实现，是由Reference自身的链表结构所实现的
Reference 的数据结构如下：
```
private T referent; //就是它所指引的
Reference next;  //指向下一个；
ReferenceQueue<? super T> queue;//这个queue是通过构造函数传入的，表示创建一个Reference时，要将其注册到那个queue上。
/* List of References waiting to be enqueued.  The collector adds
 * References to this list, while the Reference-handler thread removes
 * them.  This list is protected by the above lock object.
 */
private static Reference pending = null;

//这个对象，定义为private，并且全局没有任何给它赋值的地方，
//根据它上面的注释，我们了解到这个变量是和垃圾回收期打交道的。

ReferenceHandler线程
这个线程在Reference类的static构造块中启动，并且被设置为高优先级和daemon状态。此线程要做的事情，是不断的检查pending 是否为null，如果pending不为null，则将pending进行enqueue，否则线程进入wait状态。

通过这2点，我们来看整个过程：

pending是由jvm来赋值的，当Reference内部的referent对象的可达状态改变时，jvm会将Reference对象放入pending链表。

结合代码eg1中的 o = null; 这一句，它使得o对象满足垃圾回收的条件，并且在后边显式的调用了 System.gc()，垃圾收集进行的时候会标记WeakReference所referent的对象o为不可达（使得wr.get()==null），并且通过 赋值给pending，触发ReferenceHandler线程处理pending。

ReferenceHandler线程要做的是将pending对象enqueue，但默认我们所提供的queue，也就是从构造函数传入的是null，实际是使用了ReferenceQueue.NULL，Handler线程判断queue为ReferenceQueue.NULL则不进行操作，只有非ReferenceQueue.NULL的queue才会将Reference进行enqueue。

ReferenceQueue.NULL相当于我们提供了一个空的Queue去监听垃圾回收器给我们的反馈，并且对这种反馈不做任何处理。要处理反馈，则必须要提供一个非ReferenceQueue.NULL的queue。

在WeakHashMap则在内部提供了一个非NULL的ReferenceQueue
```

在 WeakHashMap 添加一个元素时，会使用 此queue来做监听器。见put方法中的下面一句：
```
tab[i] = new Entry<K,V>(k, value, queue, h, e);
```
这里Entry是一个内部类，继承了WeakReference
```
class Entry<K,V> extends WeakReference<K> implements Map.Entry<K,V>
```
WeakHashMap的 put, size, clear 都会间接或直接的调用到 expungeStaleEntries()方法。

expungeStaleEntries顾名思义，此方法的作用就是将 queue中陈旧的Reference进行删除，因为其内部的referent都已经不可达了。所以也将这个WeakReference包装的key从map中删除。

ReferenceQueue是作为 JVM GC与上层Reference对象管理之间的一个消息传递方式，它使得我们可以对所监听的对象引用可达发生变化时做一些处理，WeakHashMap正是利用此来实现的。
## SparseArray
SparseArray比HashMap更省内存，在某些条件下性能更好，主要是因为它避免了对key的自动装箱（int转为Integer类型），它内部则是通过两个数组来进行数据存储的，一个存储key，另外一个存储value，为了优化性能，它内部对数据还采取了压缩的方式来表示稀疏数组的数据，从而节约内存空间，我们从源码中可以看到key和value分别是用数组表示：
```
    private int[] mKeys;
    private Object[] mValues;
```

## ArrayMap
ArrayMap设计思想：SimpleArrayMap采用了两个数组来进行hash值与key、value值得保存，另外，数组大小超过8时，并需要进行重新分配空间时，只增大当前数组大小的一半，并对大小为4和8的数组进行缓存。这样最后带来的好处就是最大程度保证了数组空间都能够被使用，一定程度上避免了内存空间的浪费。 
ArrayMap数据结构：使用了两个数组，一个是Hash数组，另一个是大小*2的Array数组，为了保证通用性，这里所使用的是Object数组。Array数组中使用key+value间隔存取的方式，偶数为即 0 -> key1 1 -> value1 2 -> key2 3 -> value2 。另外Hash数组，则是对应的Key的Hash值数组，并且这是一个有序的int数组，这样在进行Key的查找时，使用二分查找则是最有效率的方式了。
进一步参考源码



